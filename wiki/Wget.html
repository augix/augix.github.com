<html>
<head>
	<link rel="Stylesheet" type="text/css" href="../../Public/templates/skinny_disqus.css" />
	<title>Wget</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>

<body>
<div class="container">
    <div class="header">
		<h1>Wget</h1> 
	</div><!-- end of header -->
	<div class="post">
	
<h1 id="toc_1">Usage</h1>
<p>
&lt;bash&gt;
sh this_script.sh &lt;URL&gt;
&lt;/bash&gt;
</p>

<h1 id="toc_2">Example</h1>
<p>
&lt;bash&gt;
sh this_script.sh <a href="http://www.affymetrix.com/Auth/support/downloads/library_files/HuEx-1_0-st-v2_libraryfile.zip">http://www.affymetrix.com/Auth/support/downloads/library_files/HuEx-1_0-st-v2_libraryfile.zip</a>
&lt;/bash&gt;
</p>

<h1 id="toc_3">Download a file in a website which requires login</h1>
<p>
wget
&lt;bash&gt;
#need wget version &gt; 1.10
</p>

<p>
#1. get cookie
</p>

<p>
~/bin/bin/wget -v -c --no-check-certificate --post-data="logon=augix.com%40gmail.com&amp;password=PASSWORD"  \
--save-cookies=cookies.txt --keep-session-cookies <a href="http://www.affymetrix.com/site/processLogin.jsp">http://www.affymetrix.com/site/processLogin.jsp</a>
</p>

<p>
#2. download file $1
</p>

<p>
~/bin/bin/wget --no-check-certificate  --cookies=on --load-cookies=cookies.txt \
--keep-session-cookies $1
&lt;/bash&gt;
</p>


<p>
curl
&lt;bash&gt;
curl -D headers_and_cookies -d "logon=augix.com%40gmail.com&amp;password=PASSWORD&amp;x=0&amp;y=0" <a href="http://www.affymetrix.com/site/processLogin.jsp">http://www.affymetrix.com/site/processLogin.jsp</a>
</p>

<p>
curl -b headers_and_cookies <a href="http://www.affymetrix.com/Auth/support/downloads/demo_data/HuEx-1_0-st-v2.tissue-mixture-data-set.gcos-files.zip">http://www.affymetrix.com/Auth/support/downloads/demo_data/HuEx-1_0-st-v2.tissue-mixture-data-set.gcos-files.zip</a>
&lt;/bash&gt;
</p>


<h1 id="toc_4">Download all the files form FTP site by Wget</h1>
<p>
 echo "wget -r -l2 --no-parent -A.bz2 <a href="ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rmacaque/fasta/"">ftp://ftp.hgsc.bcm.tmc.edu/pub/data/Rmacaque/fasta/"</a> | at now
</p>

<p>
You want to download all the GIFs from a directory on an HTTP server. You tried 
&lt;pre&gt;wget <a href="http://www.server.com/dir/*.gif&lt;/pre&gt;">http://www.server.com/dir/*.gif&lt;/pre&gt;</a>
but that didn't work because HTTP retrieval does not support globbing. In that case, use:
</p>

<p>
 wget -r -l1 --no-parent -A.gif <a href="http://www.server.com/dir/">http://www.server.com/dir/</a>
</p>

<p>
More verbose, but the effect is the same. <code>-r -l1' means to retrieve recursively (see section Recursive Retrieval), with maximum depth of 1. </code>--no-parent' means that references to the parent directory are ignored (see section Directory-Based Limits), and <code>-A.gif' means to download only the GIF files. </code>-A "*.gif"' would have worked too.
</p>

<p>
 wget -r -l1 --no-parent -A.gz <a href="ftp://hgdownload.cse.ucsc.edu/goldenPath/hg18/vsPanTro2/axtNet/">ftp://hgdownload.cse.ucsc.edu/goldenPath/hg18/vsPanTro2/axtNet/</a> -o wget.log
</p>

<h1 id="toc_5">Download the whole Website</h1>
<p>
 wget -r -p -np -k url
</p>


<h1 id="toc_6">Reference</h1>
<p>
<a href="http://www.lifehacker.com/software/top/geek-to-live--mastering-wget-161202.php">Mastering Wget - Lifehacker.com</a>
</p>

<p>
<a href="http://ftp.gnu.org/gnu/Manuals/wget-1.8.1/html_chapter/wget_7.html">http://ftp.gnu.org/gnu/Manuals/wget-1.8.1/html_chapter/wget_7.html</a>
</p>

	</div><!-- end of post -->
<br>

</div><!-- end of container -->

</body>
</html>
