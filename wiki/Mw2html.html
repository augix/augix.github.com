<html>
<head>
	<link rel="Stylesheet" type="text/css" href="../templates/skinny_disqus.css" />
	<title>Mw2html</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>

<body>
<a name='top'></a>
<div class="container">
    <div class="header">
		<h1>Mw2html</h1> 
	</div><!-- end of header -->
	<div class="post"><!-- start of post -->
	
<p>
&lt;python&gt;
#! /usr/bin/env python
</p>

<p>
"""
mw2html - Mediawiki to static HTML
</p>

<p>
I use this to create a personal website from a local mediawiki
installation.  No search functionality.  Hacks the Monobook skin and
the produced HTML.
</p>

<p>
Connelly Barnes 2005.  Public domain.
"""
</p>

<p>
_<em>version</em>_ = '0.1.0.0'
</p>

<p>
import re
import sys
import getopt
import random
import urllib
import urllib2
import textwrap
import urlparse
import os, os.path
import errno
import sha
</p>

<p>
try:
  set
except:
  from sets import Set as set
</p>

<p>
try:
  import htmldata
except:
  print 'Requires Python htmldata module:'
  print '  <a href="http://oregonstate.edu/~barnesc/htmldata/'">http://oregonstate.edu/~barnesc/htmldata/'</a>
  sys.exit()
</p>

<p>
MOVE_HREF          = 'movehref'
MADE_BY_COMMENT    = '&lt;!-- Content generated by Mediawiki and mw2html --&gt;'
INDEX_HTML = 'index.html'
url_filename_cache = {}
wrote_file_set     = set()
</p>

<p>
MONOBOOK_SKIN      = 'monobook'    # Constant identifier for Monobook.
</p>

<p>
class Config:
  """
  Instances contain all options passed at the command line.
  """
  def _<em>init</em>_(self, rooturl, outdir,
</p>
<blockquote>
flatten=True, lower=True, index=None, clean=True,
sidebar=None, hack_skin=True,
made_by=True, overwrite=False, footer=None,
skin=MONOBOOK_SKIN, move_href=True,
remove_png=True, remove_history=True):
self.rooturl         = rooturl
self.outdir          = os.path.abspath(outdir)
self.flatten         = flatten
self.lower           = lower
self.index           = index
self.clean           = clean
self.sidebar         = sidebar
self.hack_skin       = hack_skin
self.made_by         = made_by
self.overwrite       = overwrite
self.footer          = footer
self.skin            = skin
self.move_href       = move_href
if self.sidebar is not None:
self.sidebar       = os.path.abspath(self.sidebar)
if self.footer is not None:
self.footer        = os.path.abspath(self.footer)
self.remove_png      = remove_png
self.remove_history  = remove_history
</blockquote>


<p>
def post_filename_transform(filename, config):
  """
  User-customizable filename transform.
</p>

<p>
  Here filename is the full filename in the output directory.
  Returns modified full filename.
  """
  return filename
</p>


<p>
def monobook_fix_html_sidebar(doc, config):
  """
  Sets sidebar for Mediawiki 1.4beta6 Monobook HTML output.
  """
  if config.made_by:
</p>
<blockquote>
doc = doc.replace('&lt;html xmlns=', MADE_BY_COMMENT + '\n&lt;html xmlns=')
</blockquote>

<p>
  SIDEBAR_ID = 'SIDEBAR' + sha.new(str(random.random())).hexdigest()
</p>

<ol>
<li>
Remove sidebar HTML
  doc = re.sub(
    r'(&lt;!-- end content --&gt;)[\s\S]+?' +
    r'(&lt;!-- end of the left \(by default at least\) column --&gt;)',
    r'\1<div class="visualClear"></div></div></div></div>' + SIDEBAR_ID + r'\2', doc)

</ol>

<p>
  pre_sidebar = """
</p>
<blockquote>
<div id="column-one">
<div id="p-cactions" class="portlet"></div>
<div class="portlet" id="p-personal"></div>
<div class="portlet" id="p-logo"></div>
<div class="portlet" id="p-nav">
</blockquote>
<p>
  """
</p>

<p>
  post_sidebar = """
</p>
<blockquote>
</div>
<div id="p-search" class="portlet"></div>
<div class="portlet" id="p-tb"></div>
</div>
&lt;!-- end left column --&gt;
</blockquote>
<p>
  """
</p>

<p>
  sidebar_content = ''
  if config.sidebar != None:
</p>
<blockquote>
f = open(config.sidebar, 'rU')
sidebar_content = f.read()
f.close()
</blockquote>

<p>
  sidebar_content = pre_sidebar + sidebar_content + post_sidebar
</p>

<p>
  doc = doc.replace(SIDEBAR_ID, sidebar_content)
</p>

<p>
  doc = re.sub(
</p>
<blockquote>
r'<div id="f-poweredbyico">[\s\S]+?(&lt;ul id="f-list">)',
r'\1', doc)
</blockquote>

<ol>
<li>
Remove edit links
  doc = re.sub(r'<div class="editsection"[\s\S]+?</div>', r'', doc)

</ol>

<ol>
<li>
Remove page has been accessed X times list item.
  doc = re.sub(r'&lt;li id="f-viewcount"&gt;[\s\S]+?&lt;/li&gt;', r'', doc)

</ol>

<ol>
<li>
Remove disclaimers list item.
  doc = re.sub(r'&lt;li id="f-disclaimer"&gt;[\s\S]+?&lt;/li&gt;', r'', doc)

</ol>

<ol>
<li>
Replace remaining text with footer, if available.
  if config.footer is not None:
    s1 = '<div id="footer">'
    s2 = '</div>'
    i1 = doc.index(s1)
    i2 = doc.index(s2, i1)
    f = open(config.footer, 'rU')
    footer_text = f.read()
    f.close()
    doc = doc[:i1+len(s1)] + footer_text + doc[i2:]

</ol>

<p>
  return doc
</p>


<p>
def fix_move_href_tags(doc, config):
  """
  Return copy of doc with all MOVE_HREF tags removed.
  """
  while '&lt;' + MOVE_HREF in doc:
</p>
<blockquote>
i1 = doc.index('&lt;' + MOVE_HREF)
i2 = doc.index('&lt;/' + MOVE_HREF, i1+1)
i3 = doc.index('&gt;', i2+1)
(start, end) = (i1, i3+1)
tags = htmldata.tagextract(doc[start:end])
assert tags[0][0] == MOVE_HREF
assert tags[-1][0] == '/' + MOVE_HREF
href = tags[0][1].get('href', '')
new_tags = []
for tag in tags[1:-1]:
if len(tag) == 2:
if 'href' in tag[1]:
if href == '':
continue
tag[1]['href'] = href
new_tags += [tag]
doc = doc[:start] + htmldata.tagjoin(new_tags) + doc[end:]
</blockquote>
<p>
  return doc
</p>


<p>
def html_remove_image_history(doc, config):
  """
  Remove image history and links to information.
  """
  doc = re.sub(r'&lt;h2&gt;Image history&lt;/h2&gt;[\s\S]+?&lt;/ul&gt;', r'', doc)
  doc = re.sub(r'&lt;h2&gt;Image links&lt;/h2&gt;[\s\S]+?&lt;/ul&gt;', r'', doc)
  return doc
</p>


<p>
def post_html_transform(doc, url, config):
  """
  User-customizable HTML transform.
</p>

<p>
  Given an HTML document (with URLs already rewritten), returns
  modified HTML document.
  """
  if config.hack_skin:
</p>
<blockquote>
if config.skin == MONOBOOK_SKIN:
doc = monobook_fix_html_sidebar(doc, config)
doc = monobook_hack_skin_html(doc, config)
else:
raise ValueError('unknown skin')
</blockquote>
<p>
  if config.move_href:
</p>
<blockquote>
doc = fix_move_href_tags(doc, config)
</blockquote>
<p>
  if config.remove_history:
</p>
<blockquote>
doc = html_remove_image_history(doc, config)
</blockquote>
<p>
  return doc
</p>


<p>
def monobook_hack_skin_html(doc, config):
  """
  Hacks Monobook HTML output: use CSS ids for hacked skin.
</p>

<p>
  See monobook_hack_skin_css.
  """
  doc = doc.replace('<div id="globalWrapper">', '<div id="globalWrapperHacked">')
  doc = doc.replace('<div id="footer">', '<div id="footerHacked">')
  doc = doc.replace('&lt;/body&gt;', '<br>&lt;/body&gt;')
  return doc
</p>


<p>
def monobook_hack_skin_css(doc, url, config):
  """
  Hacks Mediawiki 1.4beta6 Monobook main CSS file for better looks.
</p>

<p>
  Removes flower background.  Defines *Hacked CSS ids, so we can add
  an orange bar at the top, and clear the orange bar right above the
  footer.
  """
  if not url.endswith('monobook/main.css'):
</p>
<blockquote>
return doc
</blockquote>

<p>
  doc = "/* Monobook skin automatically modified by mw2html. */" + doc
  doc = doc.replace('url("headbg.jpg")', '')
</p>

<p>
  doc += """
</p>
<blockquote>
/* Begin hacks by mw2html */
</blockquote>
<blockquote>
#globalWrapperHacked {
font-size:127%;
width: 100%;
background-color: White;
border-top: 1px solid #fabd23;
border-bottom: 1px solid #fabd23;
margin: 0.6em 0em 1em 0em;
padding: 0em 0em 1.2em 0em;
}
</blockquote>
<blockquote>
#footerHacked {
background-color: White;
margin: 0.6em 0em 0em 0em;
padding: 0.4em 0em 0em 0em;
text-align: center;
font-size: 90%;
}
</blockquote>
<blockquote>
#footerHacked li {
display: inline;
margin: 0 1.3em;
}
"""
</blockquote>

<p>
  c1 = '#column-one { padding-top: 160px; }'
  c2 = '#column-one { padding-top: 3.0em; }'
  assert c1 in doc
</p>

<p>
  doc = doc.replace(c1, '/* edit by mw2html */\n' + c2 +
</p>
<blockquote>
'\n/* end edit by mw2html */\n')
</blockquote>

<ol>
<li>
Remove external link icons.
  if config.remove_png:
    doc = re.sub(r'#bodyContent a\[href \^="<a href="http://"\][\s\S]+?\}'">http://"\][\s\S]+?\}'</a>, r'', doc)

</ol>

<p>
  return doc
</p>


<p>
def post_css_transform(doc, url, config):
  """
  User-customizable CSS transform.
</p>

<p>
  Given a CSS document (with URLs already rewritten), returns
  modified CSS document.
  """
  if config.hack_skin:
</p>
<blockquote>
if config.skin == MONOBOOK_SKIN:
doc = monobook_hack_skin_css(doc, url, config)
else:
raise ValueError('unknown skin')
</blockquote>
<p>
  return doc
</p>


<p>
def url_to_filename(url, config):
  """
  Translate a full url to a full filename (in local OS format) under outdir.
  """
  url = split_section(url)[0]
  if url in url_filename_cache:
</p>
<blockquote>
return url_filename_cache[url]
</blockquote>

<p>
  part = url
  if part.lower().startswith('<a href="http://'):">http://'):</a>
</p>
<blockquote>
part = part[len('<a href="http://'):">http://'):</a>]
</blockquote>
<p>
  L = part.strip('/').split('/')
  L = [urllib.quote_plus(x) for x in L]
  if len(L) &lt;= 1 or not '.' in L[-1]:
</p>
<ol>
<li>
url ends with a directory name.  Store it under index.html.
    L += [INDEX_HTML]

</ol>

<ol>
<li>
Local filename relative to outdir

<li>
(More transformations are made to this below...).
  subfile = os.sep.join(L)

</ol>

<ol>
<li>
Fix up extension based on mime type.
  fix_ext = True
  try:
    f = urllib2.urlopen(url)
  except urllib2.URLError, e:
    fix_ext = False

</ol>

<p>
  if fix_ext:
</p>
<blockquote>
mimetype = f.info().type.lower().split(' ')[0]
</blockquote>

<ol>
<li>
Maps mimetype to file extension
    MIME_MAP = {
     'image/jpeg': 'jpg', 'image/png': 'png', 'image/gif': 'gif',
     'image/tiff': 'tiff', 'text/plain': 'txt', 'text/html': 'html',
     'text/rtf': 'rtf', 'text/css': 'css', 'text/sgml': 'sgml',
     'text/xml': 'xml', 'application/zip': 'zip'
    }

</ol>
<blockquote>
if mimetype in MIME_MAP:
(root, ext) = os.path.splitext(subfile)
ext = '.' + MIME_MAP[mimetype]
subfile = root + ext
</blockquote>

<p>
  if config.lower:
</p>
<blockquote>
subfile = subfile.lower()
</blockquote>

<p>
  ans = os.path.join(config.outdir, subfile)
</p>

<p>
  if config.flatten:
</p>
<blockquote>
ans = flatten_filename(url, config, ans)
</blockquote>

<p>
  if config.clean:
</p>
<blockquote>
ans = clean_filename(url, config, ans)
</blockquote>

<p>
  if config.index != None:
</p>
<blockquote>
ans = move_to_index_if_needed(config, ans)
</blockquote>

<p>
  ans = find_unused_filename(ans, file_exists_in_written_set)
</p>

<p>
  ans = post_filename_transform(ans, config)
</p>

<ol>
<li>
Cache and return answer.
  wrote_file_set.add(os.path.normcase(os.path.normpath(ans)))
  url_filename_cache[url] = ans
  return ans

</ol>


<p>
def file_exists_in_written_set(filename):
  return os.path.normcase(os.path.normpath(filename)) in wrote_file_set
</p>


<p>
def find_unused_filename(filename, exists=os.path.exists):
  """
  Return 'file' if 'file' doesn't exist, otherwise 'file1', 'file2', etc.
</p>

<p>
  Existance is determined by the callable exists(), which takes
  a filename and returns a boolean.
  """
  if not exists(filename):
</p>
<blockquote>
return filename
</blockquote>
<p>
  (head, tail) = os.path.split(filename)
  i = 1
  while True:
</p>
<blockquote>
numbered = (os.path.splitext(tail)[0] + str(i) +
os.path.splitext(tail)[1])
fullname = os.path.join(head, numbered)
if not exists(fullname):
return fullname
i += 1
</blockquote>


<p>
def clean_filename(url, config, ans):
</p>
<ol>
<li>
Split outdir and our file/dir under outdir

<li>
(Note: ans may not be a valid filename)
  (par, ans) = (ans[:len(config.outdir)], ans[len(config.outdir):])
  if ans.startswith(os.sep):
    ans = ans[1:]

</ol>

<ol>
<li>
Replace % escape codes with underscores, dashes with underscores.
  while '%%' in ans:
    ans = ans[:ans.index('%%')] + '_' + ans[ans.index('%%')+2:]
  while '%25' in ans:
    ans = ans[:ans.index('%25')] + '_' + ans[ans.index('%25')+5:]
  while '%' in ans:
    ans = ans[:ans.index('%')] + '_' + ans[ans.index('%')+3:]
  ans = ans.replace('-', '_')
  while '__' in ans:
    ans = ans.replace('_<em>', '</em>')
  while '_.' in ans:
    ans = ans.replace('_.', '.')

</ol>

<ol>
<li>
Rename math thumbnails
  if '/math/' in url:
    tail = os.path.split(ans)[1]
    if os.path.splitext(tail)[1] == '.png':
      tail = os.path.splitext(tail)[0]
      if set(tail) &lt;= set('0123456789abcdef') and len(tail) == 32:
        ans = 'math_' + sha.new(tail).hexdigest()[:4] + '.png'
  return os.path.join(par, ans)

</ol>


<p>
def move_to_index_if_needed(config, ans):
  if ans.endswith(config.index):
</p>
<blockquote>
ans = ans[:len(ans)-len(config.index)] + INDEX_HTML
</blockquote>
<p>
  return ans
</p>


<p>
def flatten_filename(url, config, filename):
  def get_fullname(relname):
</p>
<blockquote>
return os.path.join(config.outdir, relname)
</blockquote>

<p>
  orig_ext = os.path.splitext(filename)[1]
  (head, tail) = os.path.split(filename)
  if tail == INDEX_HTML:
</p>
<blockquote>
(head, tail) = os.path.split(head)
</blockquote>
<p>
  ans = tail
  if os.path.splitext(ans)[1] != orig_ext:
</p>
<blockquote>
ans = os.path.splitext(ans)[0] + orig_ext
</blockquote>
<p>
  return os.path.join(config.outdir, ans)
</p>


<p>
def split_section(url):
  """
  Splits into (head, tail), where head contains no '#' and is max length.
  """
  if '#' in url:
</p>
<blockquote>
i = url.index('#')
return (url[:i], url[i:])
</blockquote>
<p>
  else:
</p>
<blockquote>
return (url, '')
</blockquote>


<p>
def rewrite_external_url(url, config):
  """
  Rewrite any URL that could not be stored locally.
</p>

<p>
  To not rewrite any external URLs, simply return url.
  """
</p>
<ol>
<li>
If could not be stored locally, but in same domain, return ''.
  if get_domain(url) == get_domain(config.rooturl):
    return ''
  return url

</ol>


<p>
def url_to_relative(url, cururl, config):
  """
  Translate a full url to a filename (in URL format) relative to cururl.
  """
  cururl = split_section(cururl)[0]
  (url, section) = split_section(url)
</p>

<p>
  L1 = url_to_filename(url,    config).replace(os.sep, '/').split('/')
  L2 = url_to_filename(cururl, config).replace(os.sep, '/').split('/')
</p>

<p>
  while L1 != [] and L2 != [] and L1[0] == L2[0]:
</p>
<blockquote>
L1 = L1[1:]
L2 = L2[1:]
</blockquote>

<p>
  return urllib.quote('../' * (len(L2) - 1) + '/'.join(L1)) + section
</p>


<p>
def parse_css(doc, url, config):
  """
  Returns (modified_doc, new_urls), where new_urls are absolute URLs for
  all links found in the CSS.
  """
  new_urls = []  
</p>

<p>
  L = htmldata.urlextract(doc, url, 'text/css')
  for item in L:
</p>
<ol>
<li>
Store url locally.
    u = item.url
    new_urls += [u]
    item.url = url_to_relative(u, url, config)

</ol>

<p>
  newdoc = htmldata.urljoin(doc, L)
  newdoc = post_css_transform(newdoc, url, config)
</p>

<p>
  return (newdoc, new_urls)
</p>


<p>
def get_domain(u):
  """
  Get domain of URL.
  """
  ans = urlparse.urlparse(u)[1]
  if ':' in ans:
</p>
<blockquote>
ans = ans[:ans.index(':')]
</blockquote>
<p>
  return ans
</p>


<p>
def should_follow(rooturl, url):
  """
  Returns boolean for whether url should be spidered.
</p>

<p>
  Given that 'url' was linked to from site 'rooturl', return whether
  'url' should be spidered as well.
  """
</p>
<ol>
<li>
False if different domains.
  if get_domain(rooturl) != get_domain(url):
    return False

</ol>

<ol>
<li>
False if multiple query fields.
  if url.count('&amp;') &gt;= 1:
    return False

</ol>

<p>
  if 'MediaWiki:' in url or 'Special:' in url:
</p>
<blockquote>
return False
</blockquote>

<p>
  return True
</p>


<p>
def parse_html(doc, url, config):
  """
  Returns (modified_doc, new_urls), where new_urls are absolute URLs for
  all links we want to spider in the HTML.
  """
  BEGIN_COMMENT_REPLACE = '&lt;BEGINCOMMENT-' + str(random.random()) + '&gt;'
  END_COMMENT_REPLACE   = '&lt;ENDCOMMENT-' + str(random.random()) + '&gt;'
</p>

<p>
  new_urls = []  
</p>

<ol>
<li>
Temporarily "get rid" of comments so htmldata will find the URLs

<li>
in the funky "&lt;!--[if" HTML hackery for IE.
  doc = doc.replace('&lt;!--', BEGIN_COMMENT_REPLACE)
  doc = doc.replace('--&gt;', END_COMMENT_REPLACE)

</ol>

<p>
  L = htmldata.urlextract(doc, url, 'text/html')
  for item in L:
</p>
<blockquote>
u = item.url
if should_follow(url, u):
</blockquote>
<ol>
<li>
Store url locally.
      new_urls += [u]
      item.url = url_to_relative(u, url, config)
    else:
      item.url = rewrite_external_url(item.url, config)

</ol>

<p>
  newdoc = htmldata.urljoin(doc, L)
  newdoc = newdoc.replace(BEGIN_COMMENT_REPLACE, '&lt;!--')
  newdoc = newdoc.replace(END_COMMENT_REPLACE, '--&gt;')
  newdoc = post_html_transform(newdoc, url, config)
</p>

<p>
  return (newdoc, new_urls)
</p>
  

<p>
def run(config, out=sys.stdout):
  """
  Code interface.
  """
  if urlparse.urlparse(config.rooturl)[1].lower().endswith('wikipedia.org'):
</p>
<blockquote>
out.write('Please do not use robots with the Wikipedia site.\n')
out.write('Instead, install the Wikipedia database locally and use mw2html on\n')
out.write('your local installation.  See the Mediawiki site for more information.\n')
sys.exit(1)
</blockquote>

<ol>
<li>
Number of files saved
  n = 0

</ol>

<p>
  if not config.overwrite and os.path.exists(config.outdir):
</p>
<blockquote>
out.write('Error: Directory exists: ' + str(config.outdir) )
sys.exit(1)
</blockquote>

<p>
  complete = set()
  pending  = set([config.rooturl])
</p>

<p>
  while len(pending) &gt; 0:
</p>
<blockquote>
url      = pending.pop()
if url in complete:
continue
complete.add(url)
try:
f        = urllib2.urlopen(url)
except urllib2.URLError, e:
try:
out.write(str(e.code) + ': ' + url + '\n\n')
except:
out.write('Error opening: ' + url + '\n\n')
continue
doc      = f.read()
mimetype = f.info().type.lower().split(' ')[0]
f.close()
</blockquote>
<blockquote>
new_urls = []
</blockquote>
<blockquote>
if mimetype == 'text/html':
(doc, new_urls) = parse_html(doc, url, config)
elif mimetype == 'text/css':
(doc, new_urls) = parse_css(doc, url, config)
</blockquote>

<ol>
<li>
Enqueue URLs that we haven't yet spidered.
    for u in new_urls:
      if u not in complete:

<ol>
<li>
Strip off any #section link.
        if '#' in u:
          u = u[:u.index('#')]
        pending.add(u)

</ol>
</ol>
<blockquote>
mode = ['wb', 'w'][mimetype.startswith('text')]
</blockquote>

<ol>
<li>
Save modified content to disk.
    filename = url_to_filename(url, config)

</ol>

<ol>
<li>
Make parent directory if it doesn't exist.
    try:
      os.makedirs(os.path.split(filename)[0])
    except OSError, e:
      if e.errno != errno.EEXIST:
        raise

</ol>

<ol>
<li>
Not really needed since we checked that the directory

<li>
outdir didn't exist at the top of run(), but let's double check.
    if os.path.exists(filename) and not config.overwrite:
      out.write('File already exists: ' + str(filename))
      sys.exit(1)

</ol>
<blockquote>
f = open(filename, mode)
f.write(doc)
f.close()
</blockquote>
<blockquote>
out.write(url + '\n =&gt; ' + filename + '\n\n')
n += 1
</blockquote>

<p>
  out.write(str(n) + ' file(s) saved\n')
</p>


<p>
def usage():
  """
  Print command line options.
  """
  usage_str = """
  mw2html url outdir [options]
</p>

<p>
  Converts an entire Mediawiki site into static HTML.
  Tested only with Mediawiki 1.4beta6 Monobook output.
  WARNING: This is a recursive robot that ignores robots.txt.  Use with care.
</p>
<blockquote>
url                  - URL of mediawiki page to convert to static HTML.
outdir               - Output directory.
</blockquote>
<blockquote>
-f, --force          - Overwrite existing files in outdir.
--no-flatten         - Do not flatten directory structure.
--no-lower           - Retain original case for output filenames and dirs.
--no-clean           - Do not clean up filenames (clean replaces
non-alphanumeric chars with _, renames math thumbs).
--no-hack-skin       - Do not modify skin CSS and HTML for looks.
--no-made-by         - Suppress "generated by" comment in HTML source.
--no-move-href       - Disable &lt;movehref&gt; tag. [1]
--no-remove-png      - Retain external link PNG icons.
--no-remove-history  - Retain image history and links to information.
-l, --left=a.html    - Paste HTML fragment file into left sidebar.
-t, --top=a.html     - Paste HTML fragment file into top horiz bar.
-b, --bottom=a.html  - Paste HTML fragment file into footer horiz bar.
-i, --index=filename - Move given filename in outdir to index.html.
</blockquote>

<p>
  Example Usage:
</p>
<blockquote>
mw2html <a href="http://127.0.0.1/mywiki/">http://127.0.0.1/mywiki/</a> out -f -i main_page.html -l sidebar.html
</blockquote>
<blockquote>
Freezes wiki into 'out' directory, moves main_page.html =&gt; index.html,
assumes sidebar.html is defined in the current directory.
</blockquote>

<p>
  [1]. The &lt;movehref&gt; tag.
</p>
<blockquote>
Wiki syntax: &lt;html&gt;&lt;movehref href="a"&gt;&lt;/html&gt;...&lt;html&gt;&lt;/movehref&gt;&lt;/html&gt;.
When enabled, this tag will cause all href= attributes inside of it to be
set to the given location.  This is useful for linking images.
In MediaWiki, for the &lt;html&gt; tag to work, one needs to enable $wgRawHtml
and $wgWhitelistEdit in LocalSettings.php.  A &lt;movehref&gt; tag with no href
field will remove all links inside it.
</blockquote>

<p>
  """
</p>

<p>
  print textwrap.dedent(usage_str.strip('\n'))
  sys.exit(1)
</p>


<p>
def main():
  """
  Command line interface.
  """
  try:
</p>
<blockquote>
(opts, args) = getopt.gnu_getopt(sys.argv[1:], 'fl:t:b:i:',
['force', 'no-flatten', 'no-lower', 'no-clean',
'no-hack-skin', 'no-made-by', 'left=',
'top=', 'bottom=', 'index=', 'no-move-href',
'no-remove-png', 'no-remove-history'])
</blockquote>
<p>
  except getopt.GetoptError:
</p>
<blockquote>
usage()
</blockquote>

<ol>
<li>
Parse non-option arguments
  try:
    (rooturl, outdir) = args
  except ValueError:
    usage()
  config = Config(rooturl=rooturl, outdir=outdir)

</ol>

<ol>
<li>
Parse option arguments
  for (opt, arg) in opts:
    if opt in ['-f', '--force']:
      config.overwrite      = True
    if opt in ['--no-flatten']:
      config.flatten        = False
    if opt in ['--no-lower']:
      config.lower          = False
    if opt in ['--no-clean']:
      config.clean          = False
    if opt in ['--no-hack-skin']:
      config.hack_skin      = False
    if opt in ['--no-made-by']:
      config.made_by        = False
    if opt in ['--no-move-href']:
      config.move_href      = False
    if opt in ['--no-remove-png']:
      config.remove_png     = False
    if opt in ['--no-remove-history']:
      config.remove_history = False
    if opt in ['-l', '--left']:
      config.sidebar        = os.path.abspath(arg)
    if opt in ['-t', '--top']:
      raise NotImplementedError
      config.header         = os.path.abspath(arg)
    if opt in ['-b', '--bottom']:
      config.footer         = os.path.abspath(arg)
    if opt in ['-i', '--index']:
      config.index          = arg

</ol>

<ol>
<li>
Run program
  run(config)

</ol>


<p>
if _<em>name</em>_ == '_<em>main</em>_':
  main()
&lt;/python&gt;
</p>

	</div><!-- end of post -->
	<div class="backhome">
		<a href="../index.html">Main Page</a><br>
        <a href="#disqus_thread" data-disqus_identifier="vimwiki: Mw2html" id="disqus_thread-show" class="showLink" onclick="showHide('disqus_thread');return true;">Comments</a>
	</div>
<br>

<!-- javascript to hide comments -->
<script language="javascript" type="text/javascript">
/*** JavaScript: Show/Hide Content ***/
function showHide(shID) {
   if (document.getElementById(shID)) {
      if (document.getElementById(shID+'-show').style.display != 'none') {
         document.getElementById(shID+'-show').style.display = 'none';
         document.getElementById(shID).style.display = 'block';
      }
      else {
         document.getElementById(shID+'-show').style.display = 'inline';
         document.getElementById(shID).style.display = 'none';
      }
   }
}
</script>

<!-- javascript to show count of comments -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'augix-wiki'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>


<a name="disqus_thread"></a>
<div id="disqus_thread" class="comment"><p align='right'><a href="#top" id="disqus_thread-hide" class="hideLink" onclick="showHide('disqus_thread');return true;">Hide Comments</a></p>
</div>

<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'augix-wiki'; // required: replace example with your forum shortname

    // The following are highly recommended additional parameters. Remove the slashes in front to use.
    // var disqus_identifier = 'unique_dynamic_id_1234';
    var disqus_identifier = "vimwiki: Mw2html";
    // var disqus_url = 'http://example.com/permalink-to-page.html';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</div><!-- end of container -->

</body>
</html>
